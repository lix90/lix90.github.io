<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="author" content="Xiang Li"><meta name="description" content="以一名数学只有普通高中水平的非理工科人的视角尝试理解机器学习之决策树。"><meta name="keywords" content="机器学习,决策树,分类算法"><title>从零学机器学习：决策树 · I'm Lix!</title><link rel="icon" href="/favicon.ico"><link rel="canonical" href="https://lix90.github.io/2016/09/22/ml决策树/"><link rel="stylesheet" href="/fonts/iconfont/iconfont.css"><link rel="stylesheet" href="/css/style.css"><script type="text/javascript">var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?443647978390b69709082ecaafe0ca1b";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script type="text/javascript">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-83416766-1', 'auto');
ga('send', 'pageview');</script></head><body><div id="main"><header><a href="/." class="logo">I'm Lix!</a><ul class="nav"><li class="nav-link"><a href="/" target="_self">Home</a></li><li class="nav-link"><a href="/archives" target="_self">Archives</a></li><li class="nav-link"><a href="/resume" target="_self">Resume</a></li><li class="nav-link"><a href="/about" target="_self">About</a></li></ul></header><section id="container"><article class="post"><h1 class="post-title">从零学机器学习：决策树</h1><span class="post-time">Sep 22, 2016</span><div class="post-content"><p>以一名数学只有普通高中水平的非理工科人的视角尝试理解机器学习之<strong>决策树</strong>。<br><a id="more"></a></p>
<p>决策树是一种比较好理解的分类算法，望文就能生意，而且意思还不会出现大的偏差。把这个算法的过程想像成一棵树或者根毛的生长过程，决策层越低，分支越丰富。决策树的优点之一也就在于此，容易理解，像我这样的非专业领域的人可以直接脑补。</p>
<p>《机器学习实战》这本书中描述，决策树的 <strong>计算复杂度</strong> 不高，输出结果易于理解（可以用直观来理解），对 <strong>中间值</strong> 的缺失不敏感（这里没懂，中间值是啥？），可以处理不相关特征数据（对数据要求不严格？）。但是，决策树虽简单，但容易产生过度匹配问题。为什么会产生过度匹配问题呢？也许是因为分类的标准太“粗糙”或者“武断”吧？？？。其适用数据类型包括 <strong>数值型</strong> 和 <strong>标称型</strong>。</p>
<p>决策树是通过对数据集的特征按照某种标准进行分类，分成若干个子数据集，子数据集又可以按照新的标准对子数据集进行分类。这里有个疑问，到底要分多少次呢？明白了，如果“决策”次数越多，决策树模型越复杂，模型越复杂，是不是就计算复杂度越高呢？这个又与“过度拟合”有关吗？直觉去看，一个数据集可以有许多特征，但是有些特征对分类并无太大的作用。举个例子，把人和动物进行区分，到底是“使用和制造工具的能力”还是“语言”？对决策树就是这样一个过程。挑选出最能够区分出类别的一批特征，然后对数据集进行分类。这样模型简单，精确度又越高。但是如何知道哪些特征最合适呢？<del>这就需要先验知识了，这里头就有了人为性。所以从这里也可以知道，决策树是一个监督学习。</del> 看到知乎里头一个问题 <a href="https://www.zhihu.com/question/19753084" target="_blank" rel="external">信息增益到底怎么理解呢？</a>，明白了，原来可以用 <strong>信息增益</strong> 来确定一个特征用于分类是不是合适。</p>
<p>前面说到，决策树适用的数据类型包括了 <strong>数值型</strong>，但是，<strong>树构造算法只适用于标称型数据，数值型数据必须离散化</strong>。也就是说，要用“身高”和“体重”来区分男女，必须把这两个数值型数据转化为离散的，例如 <code>&gt;170cm</code>，<code>&lt;170cm</code>，体重 <code>&gt;60kg</code>，<code>&lt;60kg</code>。或者稍微精细一点，按照 10cm 和 5kg 的精度进行分割。</p>
<p>阅读《机器学习实战》的过程中，有个概念很抽象，<strong>信息增益</strong>。我尝试去这样理解。如果没有 <strong>生物分类学</strong>，人对物种的认识和理解是杂乱的，可能每个人的主观分类都不一致，因为不同人关注于不同特征。但有了一个分类系统，本来看似乱套的系统，就有了规律，这样就有了标准，形成了可以共享的知识。在这里 “信息” 就是 “不同的生物”，“增益” 就是促进了对生物物种的认识，产生了可以交流和分享的知识。看起来，<strong>信息增益</strong> 是一个褒义词呀，信息增益越高越好。那怎么量化信息增益呢？这里又出现一个更加抽象难以理解的概念 <strong>熵</strong>。最开始见到这个词的时候，我竟担心自己读错。所以，顿时发现，隔行如隔山的罪魁祸首之一就是这些该死的专业术语了。越专业越不好好说话。不过，命名一些专业术语把知识简化，也是为了本专业内沟通的效率吧（活学活用，提高信息增益）。</p>
<p>那么什么是 <strong>信息熵</strong>？看定义，熵为信息的期望值（期望值即平均值，高中数学的水平，平均值对我来说比较好理解）。在文科生眼里，<strong>信息</strong> 用公式定义真是碉堡了。好了，不想数学公式了。总之，这里把信息当作概率去看待了。我只想明白，熵的大小意味着什么。维基百科的信息熵词条里有几句话：1. 熵最好理解为不确定性的度量而不是确定性的度量，因为越随机的信源的熵越大；2. 比较不可能发生的事情，当它发生了，会提供更多的信息。拿自己所知道的一点点背景知识理解的话，也就是小概率事件发生了，熵就变大了，熵变大了，事情就越发不可预测了，因为越随机了。也就是说，我越懵逼，熵就越大？这个世界乱成一团遭，那么熵就越大了。看来，<strong>熵</strong> 是个贬义词呀，哈哈。像那些信息量大的话，还是不说为好，毕竟熵大，有些人难以理解，毕竟不是所有人都有那么有内涵。那么用熵来量化信息增益，就是，熵变得越小，信息增益就越大。我们为的把世界看清楚，就得让熵变小。但是现实很残酷，我们无法预测未来，熵是不以我们的意志为转移的，该死的熵跟房价一样，死也降不下来啊。不过提高自身实力，认清自我，未来就不那么迷茫了，重要的是脚踏实地嘛。熵自然而然就小了。好吧，扯远了。总之，熵和信息增益是个对立的关系。</p>
<hr>
<p>待续</p>
<hr>
<p>参考资料：</p>
<ul>
<li>《机器学习实战》</li>
<li><a href="https://zh.wikipedia.org/wiki/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA" target="_blank" rel="external">熵 (信息论)</a>)</li>
</ul>
</div></article><div class="tags"><a href="/tags/机器学习/">机器学习</a><a href="/tags/决策树/">决策树</a><a href="/tags/分类算法/">分类算法</a></div><div class="paginator"><a href="/2016/09/17/learn-a-new-lang/" class="next"><span>Next</span><i class="iconfont icon-right"></i></a></div><section id="comments"><div id="disqus_thread"></div></section><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://lix90.github.io/2016/09/22/ml决策树/';
    this.page.identifier = '2016/09/22/ml决策树/';
    this.page.title = '从零学机器学习：决策树';
};
(function() {
var d = document, s = d.createElement('script');

s.src = '//lix90.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();</script></section><footer><div class="copyright"><p class="power">Powered by <a href="https://hexo.io/">Hexo</a> and Theme by <a href="https://github.com/ahonn/hexo-theme-even"> Even</a></p><p class="since">&copy;2016<span class="heart"><i class="iconfont icon-heart"></i></span><span class="author">Xiang Li</span></p></div><label id="back2top"><i class="iconfont icon-up"></i></label></footer></div><script src="/js/zepto.min.js"></script><script src="/js/theme.js"></script></body></html>